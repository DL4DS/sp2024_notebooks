{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import shutil\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import wandb\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Datasets\n",
    "trainset = torchvision.datasets.FashionMNIST(root='.', train=True, transform=transform)\n",
    "testset = torchvision.datasets.FashionMNIST(root='.', train=False, transform=transform)\n",
    "\n",
    "# Dataloaders to feed the data in batches\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1000, shuffle=True, num_workers=4)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mxavierohan\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "!wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "    \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "\n",
    "        self.fc1 = nn.Linear(12 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 60)\n",
    "        self.fc3 = nn.Linear(60, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = x.reshape(-1, 12 * 4 * 4)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(network, epoch, criterion, optimizer, trainloader):\n",
    "    network.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = network(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "    total_loss = running_loss / len(trainloader)\n",
    "    accuracy = 100 * correct / total\n",
    "    return total_loss, accuracy\n",
    "\n",
    "def validate(network, epoch, criterion, testloader):\n",
    "    network.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(testloader, 0):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = network(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    total_loss = running_loss / len(testloader)\n",
    "    accuracy = 100 * correct / total\n",
    "    return total_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Elapsed : 38.5441s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d9ff692bfff44858278be436b8e841d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113776463187404, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Elapsed : 40.0877s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d024b9d075e8489091f327db58c9b122",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113681509676907, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Elapsed : 39.8059s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "num_runs = 3\n",
    "\n",
    "import os\n",
    "os.environ[\"WANDB_SILENT\"] = \"true\"\n",
    "\n",
    "for run in range(num_runs):\n",
    "\n",
    "    # Set different seeds for each run\n",
    "    torch.manual_seed(run)\n",
    "\n",
    "    # Initialize a new wandb run\n",
    "    wandb.init(name=f'run_{run}', project=\"ds598\", group=\"experiment_1\", job_type=\"run_{}\".format(run+1),)\n",
    "\n",
    "    # optional\n",
    "    wandb.config.lr = 0.01\n",
    "    \n",
    "    network = Network().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(network.parameters(), wandb.config.lr)\n",
    "\n",
    "    # Log the network weight histograms (optional)\n",
    "    wandb.watch(network)\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        loss_train, acc_train = train(network, epoch, criterion, optimizer, trainloader)\n",
    "        loss_valid, acc_valid = validate(network, epoch, criterion, testloader)\n",
    "        \n",
    "        # Log metrics to wandb\n",
    "        wandb.log({\n",
    "            \"Epoch\": epoch,\n",
    "            \"Train Loss\": loss_train,\n",
    "            \"Train Acc\": acc_train,\n",
    "            \"Valid Loss\": loss_valid,\n",
    "            \"Valid Acc\": acc_valid\n",
    "        })\n",
    "    \n",
    "    print(\"Time Elapsed : {:.4f}s\".format(time.time() - start_time))\n",
    "    \n",
    "    # Finish the current run before starting the next\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy across runs: 86.31 ± 0.30\n"
     ]
    }
   ],
   "source": [
    "api = wandb.Api()\n",
    "project_name = \"ds598\"\n",
    "runs = api.runs(\"xavierohan/\" + project_name, {\"group\": \"experiment_1\"})\n",
    "\n",
    "valid_accuracies = []\n",
    "\n",
    "for run in runs:\n",
    "    # Assuming you want to analyze the validation accuracy at the last epoch\n",
    "    # If you want to do this for every epoch, you would collect all epochs' accuracies\n",
    "    history = run.scan_history(keys=[\"Valid Acc\"])\n",
    "    valid_acc = [x[\"Valid Acc\"] for x in history]\n",
    "    if valid_acc:\n",
    "        # Taking the last epoch's accuracy\n",
    "        valid_accuracies.append(valid_acc[-1])\n",
    "\n",
    "if valid_accuracies:\n",
    "    mean_acc = np.mean(valid_accuracies)\n",
    "    std_acc = np.std(valid_accuracies)\n",
    "    print(f'Validation Accuracy across runs: {mean_acc:.2f} ± {std_acc:.2f}')\n",
    "else:\n",
    "    print(\"No validation accuracies found. Please check your wandb setup and project name.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds598",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
