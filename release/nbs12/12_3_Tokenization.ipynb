{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While editing this notebook, don't change cell types as that confuses the autograder.\n",
    "\n",
    "Before you turn this notebook in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel $\\rightarrow$ Restart) and then **run all cells** (in the menubar, select Cell $\\rightarrow$ Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Understanding Deep Learning_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/DL4DS/sp2024_notebooks/blob/main/release/nbs12/12_3_Tokenization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "t9vk9Elugvmi",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "43739d5477da494f099c888ae5c65108",
     "grade": false,
     "grade_id": "cell-43e8103189a2434c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Notebook 12.3: Tokenization\n",
    "\n",
    "This notebook builds set of tokens from a text string as in figure 12.8 of the book,\n",
    "employing a simplified version of the byte pair encoding algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "3_WkaFO3OfLi",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5c0f95f6e614b09850d2f4be43d6c638",
     "grade": false,
     "grade_id": "cell-2d17781c736026c2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import re, collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "tVZVuauIXmJk",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a561c709baa6bb37f940cdfe377757f4",
     "grade": false,
     "grade_id": "cell-82d351e5a84059d0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "text = \"a sailor went to sea sea sea \"+\\\n",
    "                  \"to see what he could see see see \"+\\\n",
    "                  \"but all that he could see see see \"+\\\n",
    "                  \"was the bottom of the deep blue sea sea sea\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aae80729d2c228a3e1e192852ffc5fdb",
     "grade": false,
     "grade_id": "cell-d7ca0f8c19720665",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(text)\n",
    "print(len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fb42481edc49cde017f599a3eef40de4",
     "grade": false,
     "grade_id": "cell-a25511a67c163932",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "fF2RBrouWV5w",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0bb96c372ebdfd54476b099b89020d49",
     "grade": false,
     "grade_id": "cell-5fe07d9db81ac9ae",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "To begin with, the tokens are the individual letters and the </w> whitespace token. To visualize this, we represent each word in terms of these tokens with spaces between the tokens to delineate them.\n",
    "\n",
    "The tokenized text is stored in a structure that represents each word as tokens together with the count of how often that word occurs.  We'll call this the *vocabulary*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "OfvXkLSARk4_",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3b02de447c5e73bede832a713484d9ba",
     "grade": false,
     "grade_id": "cell-826930b99f7f7276",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def initialize_vocabulary(text):\n",
    "  \"\"\"\n",
    "  Initialize the vocabulary for the BPE algorithm.\n",
    "   \n",
    "  Initialize the vocabulary from the text string we will be using to 'train' \n",
    "  the algorithm. The vocabulary is a dictionary.  The keys are the words in the\n",
    "  text and the values are the frequency of the word in the text.\n",
    "\n",
    "  Returns:\n",
    "  vocab: A dictionary where the keys are the words in the text and the values\n",
    "          are the frequency of the word in the text.\n",
    "  \"\"\"\n",
    "  vocab = collections.defaultdict(int)\n",
    "  words = text.strip().split()\n",
    "  for word in words:\n",
    "      vocab[' '.join(list(word)) + ' </w>'] += 1\n",
    "  return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "aydmNqaoOpSm",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e54f98132e2cb459ca250bd31d42c522",
     "grade": false,
     "grade_id": "cell-44c64a188d21acb3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "vocab = initialize_vocabulary(text)\n",
    "print('Vocabulary: {}'.format(vocab))\n",
    "print('Size of vocabulary: {}'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "fJAiCjphWsI9",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bcc7b02ea3a03f59fd689c5e00d5d479",
     "grade": false,
     "grade_id": "cell-12b9c63e5cd5d749",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Find all the tokens in the current vocabulary and their frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "qYi6F_K3RYsW",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d5698dbb8b382c8ba3ff166dd6dec44c",
     "grade": false,
     "grade_id": "cell-e935d83eff4b3713",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_tokens_and_frequencies(vocab):\n",
    "  \"\"\"\n",
    "  Get the tokens and their frequencies from the vocabulary.\n",
    "  \n",
    "  Returns:\n",
    "  tokens: A dictionary where the keys are the tokens and the values are the\n",
    "          frequency of the token in the vocabulary.\n",
    "  \"\"\"\n",
    "  tokens = collections.defaultdict(int)\n",
    "  for word, freq in vocab.items():\n",
    "      word_tokens = word.split()\n",
    "      for token in word_tokens:\n",
    "          tokens[token] += freq\n",
    "  return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Y4LCVGnvXIwp",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e35c662b91caaf90c0cd5a80fa73e991",
     "grade": false,
     "grade_id": "cell-cf435e2a465808ba",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "tokens = get_tokens_and_frequencies(vocab)\n",
    "print('Tokens: {}'.format(tokens))\n",
    "print('Number of tokens: {}'.format(len(tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "_-Rh1mD_Ww3b",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3bc621033585a8a4e62b50120674fe2d",
     "grade": false,
     "grade_id": "cell-6202f3a1a91e8460",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Find each pair of adjacent tokens in the vocabulary\n",
    "and count them.  We will subsequently merge the most frequently occurring pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "OqJTB3UFYubH",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2e63d3f81d1b07e5d7ecec6f2f3b1e95",
     "grade": false,
     "grade_id": "cell-4c6061010cf1cdd7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_pairs_and_counts(vocab):\n",
    "    \"\"\"\n",
    "    Get the pairs of symbols and their counts from the vocabulary.\n",
    "    \n",
    "    Returns:\n",
    "    pairs: A dictionary where the keys are the pairs of symbols and the values\n",
    "            are the frequency of the pair in the vocabulary.\n",
    "    \"\"\"\n",
    "    pairs = collections.defaultdict(int)\n",
    "    for word, freq in vocab.items():\n",
    "        symbols = word.split()\n",
    "        for i in range(len(symbols)-1):\n",
    "            pairs[symbols[i],symbols[i+1]] += freq\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "d-zm0JBcZSjS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5ade8b8111973d0b9f3e31378210231f",
     "grade": false,
     "grade_id": "cell-108385ca10ed0a65",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "pairs = get_pairs_and_counts(vocab)\n",
    "print(f'Pairs: {pairs}')\n",
    "print(f'Number of distinct pairs: {len(pairs)}')\n",
    "\n",
    "most_frequent_pair = max(pairs, key=pairs.get)\n",
    "print(f'Most frequent pair: {most_frequent_pair}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "pcborzqIXQFS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c408ffa9faa2921a14ef7e06fae2e320",
     "grade": false,
     "grade_id": "cell-f91451269d61a640",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Merge the instances of the best pair in the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "xQI6NALdWQZX",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "047569ac7bf0d1a9ecaa5f3ccf88c237",
     "grade": false,
     "grade_id": "cell-68e5e94e09aaaf74",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def merge_pair_in_vocabulary(pair, vocab_in):\n",
    "    \"\"\"\n",
    "    Merge a pair of symbols in the vocabulary.\n",
    "    \n",
    "    Returns:\n",
    "    vocab_out: A dictionary where the keys are the updated tokens in the \n",
    "               vocabulary and the values are the frequency of the token in the\n",
    "               vocabulary.\n",
    "    \"\"\"\n",
    "    vocab_out = {}\n",
    "    bigram = re.escape(' '.join(pair))\n",
    "    p = re.compile(r'(?<!\\S)' + bigram + r'(?!\\S)')\n",
    "    for word in vocab_in:\n",
    "        word_out = p.sub(''.join(pair), word)\n",
    "        vocab_out[word_out] = vocab_in[word]\n",
    "    return vocab_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "TRYeBZI3ZULu",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cfa3617c275ca33baf58be3bbab8b853",
     "grade": false,
     "grade_id": "cell-d9a169b5cd3682f6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "vocab = merge_pair_in_vocabulary(most_frequent_pair, vocab)\n",
    "print(f'Vocabulary: {vocab}')\n",
    "print(f'Size of vocabulary: {len(vocab)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "bkhUx3GeXwba",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "438b967d0ebfe7807f07d6fcfec4ff91",
     "grade": false,
     "grade_id": "cell-84ec1c0d6152a4d8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Update the tokens, which now include the best token 'se'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Fqj-vQWeXxQi",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8f17f36e53eaf7ce361a87b45774783b",
     "grade": false,
     "grade_id": "cell-df5f590521afa12a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "tokens = get_tokens_and_frequencies(vocab)\n",
    "print(f'Tokens: {tokens}')\n",
    "print(f'Number of tokens: {tokens}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "974509e0e8333aac71dd3d62c43e38b1",
     "grade": false,
     "grade_id": "cell-1bb83a53a565587d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Byte Pair Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "K_hKp2kSXXS1",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0e31396933a66bd100a88c3168265fbf",
     "grade": false,
     "grade_id": "cell-1c5dec87d4056965",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now let's write the full tokenization routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "U_1SkQRGQ8f3",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f524f4525bf58711269cb3c3468681b6",
     "grade": false,
     "grade_id": "cell-db0c5fc117853193",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO -- write this routine by filling in this missing parts,\n",
    "# calling the above routines\n",
    "def tokenize(text, num_merges):\n",
    "  # Initialize the vocabulary from the input text\n",
    "  # vocab = (your code here)\n",
    "  vocab = initialize_vocabulary(text)\n",
    "\n",
    "  for i in range(num_merges):\n",
    "    # Find the tokens and how often they occur in the vocabulary\n",
    "    # tokens = (your code here)\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    # Find the pairs of adjacent tokens and their counts\n",
    "    # pairs = (your code here)\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    # Find the most frequent pair\n",
    "    # most_frequent_pair = (your code here)\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    print(f'Iter {i}: Most frequent pair: {most_frequent_pair}')\n",
    "\n",
    "    # Merge the code in the vocabulary\n",
    "    # vocab = (your code here)\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "  # Find the tokens and how often they occur in the vocabulary one last time\n",
    "  # tokens = (your code here)\n",
    "  tokens = get_tokens_and_frequencies(vocab)\n",
    "\n",
    "  return tokens, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "w0EkHTrER_-I",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f2f767fdeef0f144f512873ffb56cfda",
     "grade": false,
     "grade_id": "cell-a971fe3a2435f483",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "tokens, vocab = tokenize(text, num_merges=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "moqDtTzIb-NG",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fbbdc7daccb4db69eb6d96dec4f57cc0",
     "grade": false,
     "grade_id": "cell-5e6671e8aa393b17",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(f'Tokens: {tokens}')\n",
    "print(f'Number of tokens: {len(tokens)}')\n",
    "print(f'Vocabulary: {vocab}')\n",
    "print(f'Size of vocabulary: {len(vocab)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cf2b6cf34b617ebaa8a613e37595c35d",
     "grade": false,
     "grade_id": "cell-78b9f04495a153f9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "After 22 merges of the tokenizer, you should have 27 tokens and the vocabulary consisting of 18 different tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "244d8c09b93c45e79accea439b5bdeab",
     "grade": true,
     "grade_id": "cell-3c872b92abe90a48",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test code. Do not edit.\n",
    "\n",
    "assert len(vocab) == 18\n",
    "assert len(tokens) == 27"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP0/KodWM9Dtr2x+8MdXXH1",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
