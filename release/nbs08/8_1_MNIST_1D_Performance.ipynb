{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While editing this notebook, don't change cell types as that confuses the autograder.\n",
    "\n",
    "Before you turn this notebook in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel $\\rightarrow$ Restart) and then **run all cells** (in the menubar, select Cell $\\rightarrow$ Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Understanding Deep Learning_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/udlbook/udlbook/blob/main/Notebooks/Chap08/8_1_MNIST_1D_Performance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "L6chybAVFJW2",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c977ea3a5ad31e465e3f4724ee56827f",
     "grade": false,
     "grade_id": "cell-c6db64138a35360e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Notebook 8.1: MNIST_1D_Performance\n",
    "\n",
    "This notebook runs a simple neural network on the MNIST1D dataset as in figure 8.2a.\n",
    "It uses code from https://github.com/greydanus/mnist1d to generate the data.\n",
    "\n",
    "Adapted from notebooks at https://github.com/udlbook/udlbook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "ifVjS4cTOqKz",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7e2245a636bf0bcb277f3b92afee779d",
     "grade": false,
     "grade_id": "cell-b46b7d9b220f41a3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Clone the mnist1d repository if it doesn't exist\n",
    "import os\n",
    "\n",
    "if not os.path.exists('mnist1d'):\n",
    "    !git clone https://github.com/greydanus/mnist1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "qyE7G1StPIqO",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "374c08d9c5dca37a8e4d7ffd9a4a8ab1",
     "grade": false,
     "grade_id": "cell-2cb6e8f6902507e8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mnist1d\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "F7LNq72SP6jO",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b5c314f2077f9bffdc3a85a90eeb22de",
     "grade": false,
     "grade_id": "cell-704a4ceef22ef029",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's generate a training and test dataset using the MNIST1D code.  The dataset gets saved as a .pkl file so it doesn't have to be regenerated each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "YLxf7dJfPaqw",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "19cc36d8d8d27e3713c544d0036830f6",
     "grade": false,
     "grade_id": "cell-4cb95d0b5fbb733e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "args = mnist1d.data.get_dataset_args()\n",
    "data = mnist1d.data.get_dataset(args, path='./mnist1d_data.pkl', download=False, regenerate=False)\n",
    "\n",
    "# The training and test input and outputs are in\n",
    "# data['x'], data['y'], data['x_test'], and data['y_test']\n",
    "print(\"Examples in training set: {}\".format(len(data['y'])))\n",
    "print(\"Examples in test set: {}\".format(len(data['y_test'])))\n",
    "print(\"Length of each example: {}\".format(data['x'].shape[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "FxaB5vc0uevl",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6841a41895a1e7d5a9d2ba882939d9e4",
     "grade": false,
     "grade_id": "cell-7c3ea9378860d4b0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "D_i = 40    # Input dimensions\n",
    "D_k = 100   # Hidden dimensions\n",
    "D_o = 10    # Output dimensions\n",
    "\n",
    "# TO DO:\n",
    "# Define a model with two hidden layers of size 100\n",
    "# And ReLU activations between them\n",
    "# Replace this line (see Figure 7.8 of book for help):\n",
    "model = torch.nn.Sequential(torch.nn.Linear(D_i, D_o))\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "def weights_init(layer_in):\n",
    "  # TO DO:\n",
    "  # Initialize the parameters with He initialization\n",
    "  # Replace this line (see figure 7.8 of book for help)\n",
    "  print(\"Initializing layer\")\n",
    "\n",
    "  # YOUR CODE HERE\n",
    "  raise NotImplementedError()\n",
    "\n",
    "# Call the function you just defined\n",
    "model.apply(weights_init)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2484fcf3416103ba6c930f55e592f86a",
     "grade": false,
     "grade_id": "cell-ff47d79f21506df4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(summary(model, input_size=(1, D_i), device='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "_rX6N3VyyQTY",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "32192e9a117a019189a65ab56ad9a33a",
     "grade": false,
     "grade_id": "cell-519ba15e1f56c6a2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# choose cross entropy loss function (equation 5.24)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# construct SGD optimizer and initialize learning rate and momentum\n",
    "# original lr = 0.05, momentum = 0.9\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.1)\n",
    "\n",
    "# object that decreases learning rate by half every 10 epochs\n",
    "# scheduler = StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "# create 100 dummy data points and store in data loader class\n",
    "x_train = torch.tensor(data['x'].astype('float32'))\n",
    "y_train = torch.tensor(data['y'].transpose().astype('long'))\n",
    "x_test= torch.tensor(data['x_test'].astype('float32'))\n",
    "y_test = torch.tensor(data['y_test'].astype('long'))\n",
    "\n",
    "# load the data into a class that creates the batches\n",
    "data_loader = DataLoader(TensorDataset(x_train,y_train), batch_size=100, shuffle=True, worker_init_fn=np.random.seed(1))\n",
    "\n",
    "# Initialize model weights\n",
    "model.apply(weights_init)\n",
    "\n",
    "# loop over the dataset n_epoch times\n",
    "n_epoch = 100 # was 50\n",
    "# store the loss and the % correct at each epoch\n",
    "losses_train = np.zeros((n_epoch))\n",
    "errors_train = np.zeros((n_epoch))\n",
    "losses_test = np.zeros((n_epoch))\n",
    "errors_test = np.zeros((n_epoch))\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "  # loop over batches\n",
    "  for i, batch in enumerate(data_loader):\n",
    "    # retrieve inputs and labels for this batch\n",
    "    x_batch, y_batch = batch\n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "    # forward pass -- calculate model output\n",
    "    pred = model(x_batch)\n",
    "    # compute the loss\n",
    "    loss = loss_function(pred, y_batch)\n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "    # SGD update\n",
    "    optimizer.step()\n",
    "\n",
    "  # Run whole dataset to get statistics -- normally wouldn't do this\n",
    "  pred_train = model(x_train)\n",
    "  pred_test = model(x_test)\n",
    "  _, predicted_train_class = torch.max(pred_train.data, 1)\n",
    "  _, predicted_test_class = torch.max(pred_test.data, 1)\n",
    "  errors_train[epoch] = 100 - 100 * (predicted_train_class == y_train).float().sum() / len(y_train)\n",
    "  errors_test[epoch]= 100 - 100 * (predicted_test_class == y_test).float().sum() / len(y_test)\n",
    "  losses_train[epoch] = loss_function(pred_train, y_train).item()\n",
    "  losses_test[epoch]= loss_function(pred_test, y_test).item()\n",
    "  print(f'Epoch {epoch:5d}, train loss {losses_train[epoch]:.6f}, train error {errors_train[epoch]:3.2f},  test loss {losses_test[epoch]:.6f}, test error {errors_test[epoch]:3.2f}')\n",
    "\n",
    "  # tell scheduler to consider updating learning rate\n",
    "  # scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "54a4689f94599adf06e0766c357a2f9d",
     "grade": true,
     "grade_id": "cell-754a905982bc643d",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Your trained model should satisfy these limits\n",
    "# Do not modify this cell\n",
    "\n",
    "assert losses_train[-1] < 0.05, \"Loss on training set is too high\"\n",
    "assert errors_train[-1] < .01, \"Error on training set is too high\"\n",
    "\n",
    "assert losses_test[-1] < 1.7, \"Loss on test set is too high\"\n",
    "assert np.min(losses_test) < 1.3, \"Minimum loss on test set is too high\"\n",
    "\n",
    "assert errors_test[-1] < 40, \"Error on test set is too high\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "yI-l6kA_EH9G",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "37cbc1e83d17961f3d79fa26b04670d9",
     "grade": false,
     "grade_id": "cell-baa7be01fee0fa02",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(errors_train,'r-',label='train')\n",
    "ax.plot(errors_test,'b-',label='test')\n",
    "ax.set_ylim(0,100); ax.set_xlim(0,n_epoch)\n",
    "ax.set_xlabel('Epoch'); ax.set_ylabel('Error')\n",
    "ax.set_title('TrainError %3.2f, Test Error %3.2f'%(errors_train[-1],errors_test[-1]))\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot the results\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(losses_train,'r-',label='train')\n",
    "ax.plot(losses_test,'b-',label='test')\n",
    "ax.set_xlim(0,n_epoch)\n",
    "ax.set_xlabel('Epoch'); ax.set_ylabel('Loss')\n",
    "ax.set_title('Train loss %3.2f, Test loss %3.2f'%(losses_train[-1],losses_test[-1]))\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "q-yT6re6GZS4",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "020629b488027218cdf69a8c96393f71",
     "grade": false,
     "grade_id": "cell-a4081a80112ce3e8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Look at the difference between training and test, and observe what is happening to test loss as training proceeds.\n",
    "\n",
    "We'll also come back and compare this to the convolutional neural network later."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNLj3HOpVB87nRu7oSLuBaU",
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
