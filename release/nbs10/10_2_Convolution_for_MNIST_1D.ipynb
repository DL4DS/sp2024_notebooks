{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While editing this notebook, don't change cell types as that confuses the autograder.\n",
    "\n",
    "Before you turn this notebook in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel $\\rightarrow$ Restart) and then **run all cells** (in the menubar, select Cell $\\rightarrow$ Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Understanding Deep Learning_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/DL4DS/sp2024_notebooks/blob/main/release/nbs10/10_2_Convolution_for_MNIST_1D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "t9vk9Elugvmi",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "382f4c1f9e2e22529c4eca847b8a0295",
     "grade": false,
     "grade_id": "cell-826721bc9c861057",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Notebook 10.2: Convolution for MNIST-1D\n",
    "\n",
    "This notebook investigates a 1D convolutional network for MNIST-1D as in figure 10.7 and 10.8a.\n",
    "\n",
    "Adapted from notebooks at https://github.com/udlbook/udlbook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "D5yLObtZCi9J",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3be57dfed972074361fe13320fdbe067",
     "grade": false,
     "grade_id": "cell-38ca5c48c4502f04",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Clone the mnist1d repository if it doesn't exist\n",
    "import os\n",
    "\n",
    "if not os.path.exists('mnist1d'):\n",
    "    !git clone https://github.com/greydanus/mnist1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "YrXWAH7sUWvU",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ae641d4a33b8951c20767dd08ca09df4",
     "grade": false,
     "grade_id": "cell-898018bfe2eae0a0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import matplotlib.pyplot as plt\n",
    "import mnist1d\n",
    "import random\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "twI72ZCrCt5z",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d528988585d87180da6af0099959a9af",
     "grade": false,
     "grade_id": "cell-dba2f652f646650b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "args = mnist1d.data.get_dataset_args()\n",
    "data = mnist1d.data.get_dataset(args, path='./mnist1d_data.pkl', download=False, regenerate=False)\n",
    "\n",
    "# The training and test input and outputs are in\n",
    "# data['x'], data['y'], data['x_test'], and data['y_test']\n",
    "print(\"Examples in training set: {}\".format(len(data['y'])))\n",
    "print(\"Examples in test set: {}\".format(len(data['y_test'])))\n",
    "print(\"Length of each example: {}\".format(data['x'].shape[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "8bKADvLHbiV5",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "33f15b626b9e30c047c82c1b3335f3b5",
     "grade": false,
     "grade_id": "cell-186d8014f879b8bc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Load in the data\n",
    "train_data_x = data['x'].transpose()\n",
    "train_data_y = data['y']\n",
    "val_data_x = data['x_test'].transpose()\n",
    "val_data_y = data['y_test']\n",
    "# Print out sizes\n",
    "print(\"Train data: %d examples (columns), each of which has %d dimensions (rows)\"%((train_data_x.shape[1],train_data_x.shape[0])))\n",
    "print(\"Validation data: %d examples (columns), each of which has %d dimensions (rows)\"%((val_data_x.shape[1],val_data_x.shape[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "_sFvRDGrl4qe",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d041e0eb4ec05e1c155d77843424d064",
     "grade": false,
     "grade_id": "cell-c8ea2152bd84384a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Define the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "FslroPJJffrh",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c1bf01f51f97e92202957cfb0bd5c2fa",
     "grade": false,
     "grade_id": "cell-6cc7ac979be00536",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# There are 40 input dimensions and 10 output dimensions for this data\n",
    "# The inputs correspond to the 40 offsets in the MNIST1D template.\n",
    "D_i = 40\n",
    "# The outputs correspond to the 10 digits\n",
    "D_o = 10\n",
    "\n",
    "\n",
    "# TODO Create a model with the following layers\n",
    "# 1. Convolutional layer, (input=length 40 and 1 channel, kernel size 3, stride 2, padding=\"valid\", 15 output channels )\n",
    "# 2. ReLU\n",
    "# 3. Convolutional layer, (input=length 19 and 15 channels, kernel size 3, stride 2, padding=\"valid\", 15 output channels )\n",
    "# 4. ReLU\n",
    "# 5. Convolutional layer, (input=length 9 and 15 channels, kernel size 3, stride 2, padding=\"valid\", 15 output channels)\n",
    "# 6. ReLU\n",
    "# 7. Flatten (converts 4x15) to length 60\n",
    "# 8. Linear layer (input size = 60, output size = 10)\n",
    "# References:\n",
    "# https://pytorch.org/docs/1.13/generated/torch.nn.Conv1d.html?highlight=conv1d#torch.nn.Conv1d\n",
    "# https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html\n",
    "# https://pytorch.org/docs/1.13/generated/torch.nn.Linear.html?highlight=linear#torch.nn.Linear\n",
    "\n",
    "# NOTE THAT THE CONVOLUTIONAL LAYERS NEED TO TAKE THE NUMBER OF INPUT CHANNELS AS A PARAMETER\n",
    "# AND NOT THE INPUT SIZE.\n",
    "\n",
    "model = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "YgLaex1pfhqz",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5edaca79d353a5efb20038a5088639d1",
     "grade": false,
     "grade_id": "cell-1657acd518aefc28",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# He initialization of weights\n",
    "def weights_init(layer_in):\n",
    "  if isinstance(layer_in, nn.Linear):\n",
    "    nn.init.kaiming_uniform_(layer_in.weight)\n",
    "    layer_in.bias.data.fill_(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "NYw8I_3mmX5c",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "568c5cef459f5a0b7ab6a39bdba88974",
     "grade": false,
     "grade_id": "cell-23c12ca27b87659a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# choose cross entropy loss function (equation 5.24 in the loss notes)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "# construct SGD optimizer and initialize learning rate and momentum\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.05, momentum=0.9)\n",
    "# object that decreases learning rate by half every 20 epochs\n",
    "scheduler = StepLR(optimizer, step_size=20, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "173cee8439025fd052f81a46983b96b2",
     "grade": false,
     "grade_id": "cell-bba067cd071fbc90",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create 100 dummy data points and store in data loader class\n",
    "x_train = torch.tensor(train_data_x.transpose().astype('float32'))\n",
    "y_train = torch.tensor(train_data_y.astype('long')).long()\n",
    "x_val= torch.tensor(val_data_x.transpose().astype('float32'))\n",
    "y_val = torch.tensor(val_data_y.astype('long')).long()\n",
    "\n",
    "# load the data into a class that creates the batches\n",
    "data_loader = DataLoader(TensorDataset(x_train,y_train), batch_size=100, shuffle=True, worker_init_fn=np.random.seed(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "64c9a0ab3fc2f0af1677d4922a7ac539",
     "grade": false,
     "grade_id": "cell-16e01f293696a21b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(len(data_loader))\n",
    "print(len(x_train))\n",
    "print(len(y_train))\n",
    "print(len(x_val))\n",
    "print(len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4c1a444c0e5d3aec20174f63a44999f3",
     "grade": false,
     "grade_id": "cell-f302fdf1bec52860",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Initialize model weights\n",
    "model.apply(weights_init)\n",
    "print(model)\n",
    "summary(model, input_size=(100, 1, 40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1771937d0163ddb19834dd1e4e604ab6",
     "grade": false,
     "grade_id": "cell-77d13e8a54937cbe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# loop over the dataset n_epoch times\n",
    "n_epoch = 100\n",
    "# store the loss and the % correct at each epoch\n",
    "losses_train = np.zeros((n_epoch))\n",
    "errors_train = np.zeros((n_epoch))\n",
    "losses_val = np.zeros((n_epoch))\n",
    "errors_val = np.zeros((n_epoch))\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "  # loop over batches\n",
    "  for i, data in enumerate(data_loader):\n",
    "    # retrieve inputs and labels for this batch\n",
    "    x_batch, y_batch = data\n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "    # forward pass -- calculate model output\n",
    "    pred = model(x_batch[:,None,:])\n",
    "    # compute the loss\n",
    "    loss = loss_function(pred, y_batch)\n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "    # SGD update\n",
    "    optimizer.step()\n",
    "\n",
    "  # Run whole dataset to get statistics -- normally wouldn't do this\n",
    "  pred_train = model(x_train[:,None,:])\n",
    "  pred_val = model(x_val[:,None,:])\n",
    "  _, predicted_train_class = torch.max(pred_train.data, 1)\n",
    "  _, predicted_val_class = torch.max(pred_val.data, 1)\n",
    "  errors_train[epoch] = 100 - 100 * (predicted_train_class == y_train).float().sum() / len(y_train)\n",
    "  errors_val[epoch]= 100 - 100 * (predicted_val_class == y_val).float().sum() / len(y_val)\n",
    "  losses_train[epoch] = loss_function(pred_train, y_train).item()\n",
    "  losses_val[epoch]= loss_function(pred_val, y_val).item()\n",
    "  print(f'Epoch {epoch:5d}, train loss {losses_train[epoch]:.6f}, train error {errors_train[epoch]:3.2f},  val loss {losses_val[epoch]:.6f}, percent error {errors_val[epoch]:3.2f}')\n",
    "\n",
    "  # tell scheduler to consider updating learning rate\n",
    "  scheduler.step()\n",
    "\n",
    "# Plot the results\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(errors_train,'r-',label='train')\n",
    "ax.plot(errors_val,'b-',label='validation')\n",
    "ax.set_ylim(0,100); ax.set_xlim(0,n_epoch)\n",
    "ax.set_xlabel('Epoch'); ax.set_ylabel('Error')\n",
    "ax.set_title('Part I: Validation Result %3.2f'%(errors_val[-1]))\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f98124720f6b6c6797ca4f0c0c078e95",
     "grade": false,
     "grade_id": "cell-f9aedc7087a3d938",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Compare the number of parameters from the model summary above and the test error\n",
    "with the fully connected model in 8_1_MNIST_1D_Performance.ipynb."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNJodaaCLMRWL9vTl8B/iLI",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
