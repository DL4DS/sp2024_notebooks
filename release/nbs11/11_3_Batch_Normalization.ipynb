{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While editing this notebook, don't change cell types as that confuses the autograder.\n",
    "\n",
    "Before you turn this notebook in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel $\\rightarrow$ Restart) and then **run all cells** (in the menubar, select Cell $\\rightarrow$ Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Understanding Deep Learning_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/udlbook/udlbook/blob/main/Notebooks/Chap11/11_3_Batch_Normalization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "t9vk9Elugvmi",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2585d13272be15429fb5574909f1f258",
     "grade": false,
     "grade_id": "cell-1e5462fd945d330f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Notebook 11.3: Batch normalization\n",
    "\n",
    "This notebook investigates the use of batch normalization in residual networks.\n",
    "\n",
    "Adapted from notebooks at https://github.com/udlbook/udlbook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "D5yLObtZCi9J",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ad0450bc15d0581ea10706d0891be094",
     "grade": false,
     "grade_id": "cell-76061d0b3421ca7c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Clone the mnist1d repository if it doesn't exist\n",
    "import os\n",
    "\n",
    "if not os.path.exists('mnist1d'):\n",
    "    !git clone https://github.com/greydanus/mnist1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "YrXWAH7sUWvU",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "543072cfc97cafccd1b380f7354693a7",
     "grade": false,
     "grade_id": "cell-33ff3433fba27559",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import matplotlib.pyplot as plt\n",
    "import mnist1d\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "twI72ZCrCt5z",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d65b5358dc6690355e7cb6d219dbd741",
     "grade": false,
     "grade_id": "cell-cd9036c70c31e5c2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "args = mnist1d.data.get_dataset_args()\n",
    "data = mnist1d.data.get_dataset(args, path='./mnist1d_data.pkl', download=False, regenerate=False)\n",
    "\n",
    "# The training and test input and outputs are in\n",
    "# data['x'], data['y'], data['x_test'], and data['y_test']\n",
    "print(\"Examples in training set: {}\".format(len(data['y'])))\n",
    "print(\"Examples in test set: {}\".format(len(data['y_test'])))\n",
    "print(\"Length of each example: {}\".format(data['x'].shape[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "8bKADvLHbiV5",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1f15b4f6ad97a52e6e63da36c59ecde4",
     "grade": false,
     "grade_id": "cell-b87888bae934ce5a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Load in the data\n",
    "train_data_x = data['x'].transpose()\n",
    "train_data_y = data['y']\n",
    "val_data_x = data['x_test'].transpose()\n",
    "val_data_y = data['y_test']\n",
    "# Print out sizes\n",
    "print(\"Train data: %d examples (columns), each of which has %d dimensions (rows)\"%((train_data_x.shape[1],train_data_x.shape[0])))\n",
    "print(\"Validation data: %d examples (columns), each of which has %d dimensions (rows)\"%((val_data_x.shape[1],val_data_x.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "3bBpJIV-N-lt",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9d4199f24cc05e3e3021897d1873dab2",
     "grade": false,
     "grade_id": "cell-e31b82745907291f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def print_variance(name, data):\n",
    "  # First dimension(rows) is batch elements\n",
    "  # Second dimension(columns) is neurons.\n",
    "  np_data = data.detach().numpy()\n",
    "  # Compute variance across neurons and average these variances over members of the batch\n",
    "  neuron_variance = np.mean(np.var(np_data, axis=0))\n",
    "  # Print out the name and the variance\n",
    "  print(\"%s variance=%f\"%(name,neuron_variance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "YgLaex1pfhqz",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a87578d02abd8c4bd881377579740f39",
     "grade": false,
     "grade_id": "cell-68bde4da9833c8d9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# He initialization of weights\n",
    "def weights_init(layer_in):\n",
    "  if isinstance(layer_in, nn.Linear):\n",
    "    nn.init.kaiming_uniform_(layer_in.weight)\n",
    "    layer_in.bias.data.fill_(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "DFlu45pORQEz",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "52ea5cad5abf8965d37c5d2b9a604813",
     "grade": false,
     "grade_id": "cell-d7912692072efbd9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def run_one_step_of_model(model, x_train, y_train):\n",
    "  # choose cross entropy loss function (equation 5.24 in the loss notes)\n",
    "  loss_function = nn.CrossEntropyLoss()\n",
    "  # construct SGD optimizer and initialize learning rate and momentum\n",
    "  optimizer = torch.optim.SGD(model.parameters(), lr = 0.05, momentum=0.9)\n",
    "\n",
    "  # load the data into a class that creates the batches\n",
    "  data_loader = DataLoader(TensorDataset(x_train,y_train), batch_size=200, shuffle=True, worker_init_fn=np.random.seed(1))\n",
    "\n",
    "  # Initialize model weights\n",
    "  model.apply(weights_init)\n",
    "\n",
    "  # Get a batch\n",
    "  for i, data in enumerate(data_loader):\n",
    "    # retrieve inputs and labels for this batch\n",
    "    x_batch, y_batch = data\n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "    # forward pass -- calculate model output\n",
    "    pred = model(x_batch)\n",
    "    # compute the loss\n",
    "    loss = loss_function(pred, y_batch)\n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "    # SGD update\n",
    "    optimizer.step()\n",
    "    # Break out of this loop -- we just want to see the first\n",
    "    # iteration, but usually we would continue\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "i7Q0ScWgRe4G",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9b245cae07354c65b865d29b5969d68a",
     "grade": false,
     "grade_id": "cell-42585b922ff752d0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# convert training data to torch tensors\n",
    "x_train = torch.tensor(train_data_x.transpose().astype('float32'))\n",
    "y_train = torch.tensor(train_data_y.astype('long'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "FslroPJJffrh",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f3273c91bfc3bc2294231285cda15ae5",
     "grade": false,
     "grade_id": "cell-065e8fe183ad32e1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This is a simple residual model with 5 residual branches in a row\n",
    "class ResidualNetwork(torch.nn.Module):\n",
    "  def __init__(self, input_size, output_size, hidden_size=100):\n",
    "    super(ResidualNetwork, self).__init__()\n",
    "    self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "    self.linear2 = nn.Linear(hidden_size, hidden_size)\n",
    "    self.linear3 = nn.Linear(hidden_size, hidden_size)\n",
    "    self.linear4 = nn.Linear(hidden_size, hidden_size)\n",
    "    self.linear5 = nn.Linear(hidden_size, hidden_size)\n",
    "    self.linear6 = nn.Linear(hidden_size, hidden_size)\n",
    "    self.linear7 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "  def count_params(self):\n",
    "    return sum([p.view(-1).shape[0] for p in self.parameters()])\n",
    "\n",
    "  def forward(self, x):\n",
    "    print_variance(\"Input\",x)\n",
    "    f = self.linear1(x)\n",
    "    print_variance(\"First preactivation\",f)\n",
    "    res1 = f+ self.linear2(f.relu())\n",
    "    print_variance(\"After first residual connection\",res1)\n",
    "    res2 = res1 + self.linear3(res1.relu())\n",
    "    print_variance(\"After second residual connection\",res2)\n",
    "    res3 = res2 + self.linear4(res2.relu())\n",
    "    print_variance(\"After third residual connection\",res3)\n",
    "    res4 = res3 + self.linear5(res3.relu())\n",
    "    print_variance(\"After fourth residual connection\",res4)\n",
    "    res5 = res4 + self.linear6(res4.relu())\n",
    "    print_variance(\"After fifth residual connection\",res5)\n",
    "    return self.linear7(res5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "NYw8I_3mmX5c",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "18acf6a3c4a37a237e9e6759e28c09ca",
     "grade": false,
     "grade_id": "cell-d83be9cde8f9196a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Define the model and run for one step\n",
    "# Monitoring the variance at each point in the network\n",
    "n_hidden = 100\n",
    "n_input = 40\n",
    "n_output = 10\n",
    "model = ResidualNetwork(n_input, n_output, n_hidden)\n",
    "run_one_step_of_model(model, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "0kZUlWkkW8jE",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fc775442fcd8496c878876da3d3d3db1",
     "grade": false,
     "grade_id": "cell-54b35c5476c72e9e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Notice that the variance roughly doubles at each step so it increases exponentially as in figure 11.6b in the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "5JvMmaRITKGd",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0242ae4e2ca6aee4c2cc6a804d582129",
     "grade": false,
     "grade_id": "cell-d71b54ed13b353b4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO Adapt the residual network to add a batch norm operation\n",
    "# before the contents of each residual link as in figure 11.6c in the book\n",
    "# Use the torch function nn.BatchNorm1d\n",
    "class ResidualNetworkWithBatchNorm(torch.nn.Module):\n",
    "  def __init__(self, input_size, output_size, hidden_size=100):\n",
    "    super(ResidualNetworkWithBatchNorm, self).__init__()\n",
    "    self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "    self.linear2 = nn.Linear(hidden_size, hidden_size)\n",
    "    self.linear3 = nn.Linear(hidden_size, hidden_size)\n",
    "    self.linear4 = nn.Linear(hidden_size, hidden_size)\n",
    "    self.linear5 = nn.Linear(hidden_size, hidden_size)\n",
    "    self.linear6 = nn.Linear(hidden_size, hidden_size)\n",
    "    self.linear7 = nn.Linear(hidden_size, output_size)\n",
    "    self.bn1 = nn.BatchNorm1d(hidden_size)\n",
    "    self.bn2 = nn.BatchNorm1d(hidden_size)\n",
    "    self.bn3 = nn.BatchNorm1d(hidden_size)\n",
    "    self.bn4 = nn.BatchNorm1d(hidden_size)\n",
    "    self.bn5 = nn.BatchNorm1d(hidden_size)\n",
    "\n",
    "  def count_params(self):\n",
    "    return sum([p.view(-1).shape[0] for p in self.parameters()])\n",
    "\n",
    "  # Copy the forward function from the previous model and add batch norm\n",
    "\n",
    "  # YOUR CODE HERE\n",
    "  raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "2U3DnlH9Uw6c",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c8a3004f01e23f2bbb8624f8a11d9b62",
     "grade": false,
     "grade_id": "cell-93c35a87157d2d63",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Define the model\n",
    "n_hidden = 100\n",
    "n_input = 40\n",
    "n_output = 10\n",
    "model = ResidualNetworkWithBatchNorm(n_input, n_output, n_hidden)\n",
    "run_one_step_of_model(model, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "R_ucFq9CXq8D",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "370d605e7d83c201afcdd8ddcc419e62",
     "grade": false,
     "grade_id": "cell-60e496689705567f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Note that the variance should now be increasing linearly as in figure 11.6c."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPVeAd3eDpEOCFh8CVyr1zz",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
