{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this notebook in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel $\\rightarrow$ Restart) and then **run all cells** (in the menubar, select Cell $\\rightarrow$ Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Understanding Deep Learning_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/DL4DS/sp2024_notebooks/blob/main/release/disc01/00_fundamentals.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# 00. Fundamentals of PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.2'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imports\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal of this notebook\n",
    "- Introduction to PyTorch\n",
    "- Understanding Tensors\n",
    "- Fundamental Tensor Operations and Methods\n",
    "- Few Questions to test your understanding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brief Introduction to PyTorch\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Origin Story\n",
    "\n",
    "Picture the early 2000s, when there was a need to develop ML frameworks that were flexible enough for daily research tasks. Out of this need, the Torch framework was born. Torch was released in 2002 out of the efforts of Ronan Collobert, Koray Kavukcuoglu, and Clement Farabet. It was later picked up by Facebook AI Research and many other people from several universities and research groups. Although Torch did give the required flexibility, it was written in Lua, which was not a very popular language, and the major drawback the community faced was the learning curve to the new language. \n",
    "\n",
    "The widespread acceptance of Pyhon in the ML community made the developers pivot to Python, and thus the Python based version of Torch a.k.a PyTorch was born. PyTorch began as an internship project by Adam Paszke, who was working under Soumith Chintala, a core developer of Torch.\n",
    "\n",
    "Ref: https://subscription.packtpub.com/book/data/9781788834131/1/ch01lvl1sec02/understanding-pytorch-s-history"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In a nutshell\n",
    "\n",
    "PyTorch is an open-source machine learning framework that allows you to write your own neural networks and optimize them efficiently. It was primarily developed by Facebook's AI Research Lab (FAIR). It is based on the Torch library, which is a scientific computing framework with wide support for machine learning algorithms. PyTorch is a Python package that provides two high-level features:\n",
    "* A replacement for NumPy to use the power of GPUs and other accelerators.\n",
    "* An automatic differentiation library that is useful to implement neural networks."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why use PyTorch?\n",
    "1. PyTorch is Pythonic: Ease of using Popular Python packages like NumPy, SciPy, etc to extend the functionality of PyTorch.\n",
    "2. Easy to Learn: Due to its easy and intuitive syntax.\n",
    "3. Strong Community Support: PyTorch has a strong community of developers and researchers who have contributed to the framework. When in doubt, you may most likely see a solution to your problem on https://discuss.pytorch.org/.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch Governence: https://pytorch.org/docs/stable/community/governance.html"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors are the basic building blocks of modern deep learning frameworks. A tensor is a generalization of vectors and matrices and is easily understood as a multidimensional array. A tensor can be a number, a vector, a matrix, or an n-dimensional array, or in general terms a container storing numerical values.\n",
    "\n",
    "Recommended viewing to understand tensors: What's a Tensor? - Dan Fleisch (https://www.youtube.com/watch?v=f5liqUk0ZTw)\n",
    "\n",
    "##### Types of Tensor:\n",
    "* Scalar / 0-D tensor: A container with a single value. (Ex: 23, 5, 2, etc)\n",
    "* Vector / 1-D tensor: A container with multiple values. (Ex: [1, 2, 3, 4, 5])\n",
    "* Matrix / 2-D tensor: A container with multiple values arranged in rows and columns. (Ex: [[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "* In general, 2-D tensors are called matrices (Matrix, if singular), and anything above 2-D are just called tensors.\n",
    "\n",
    "##### Rank of a Tensor:\n",
    "\n",
    "A tensor of rank 1 is a vector, which is a one-dimensional array, \n",
    "```python\n",
    "[a,b]\n",
    "```\n",
    "A tensor of rank 2 is a vector of vectors, or a matrix, or a two-dimensional array,\n",
    "```python\n",
    "[[a,b],[c,d]]\n",
    "```\n",
    "A tensor of rank 3 is a vector of vectors of vectors, so something with three nestings,\n",
    "```python\n",
    "[[[a,b],[c,d]],[[e,f],[g,h]]]\n",
    "```\n",
    "and so on...\n",
    "\n",
    "Broadly, a tensor can be understood to be a vector of vectors of vectors of vectors... and so on. The rank is the number of nestings of \"of vectors\". \n",
    "\n",
    "Or in other words, Rank can be described as the number of information needed to specify a particular element of a tensor. For example, to specify an element in a 2-D tensor, we need 2 pieces of information, the row and the column. So, the rank of a 2-D tensor is 2.\n",
    "\n",
    "#### Pitfall:\n",
    "##### Are Matrices and 2-D tensors the same?    \n",
    "\n",
    "A 2-D tensor can be represented by a matrix, but there is more to a tensor than just its arrangement of numerical values. A tensor is a geometric object, whose components obey certain transformation laws. A matrix is just a collection of numbers in a rectangular array, there's no inherent rule that they have to obey any transformation rules.\n",
    "\n",
    "Video is a series of images correlated over time. We can use tensors to represent that correlation better and more intuitively than trying to convert it down to two-dimensional matrices. A third-rank tensor can encode all the aspects of each image (height, width, and color), while a rank-4 tensor could also hold information about time or order for the images."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.], requires_grad=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor([1, 2, 3],\n",
    "                 dtype=torch.float32,\n",
    "                 device='cpu',\n",
    "                 requires_grad=True)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of scalar: torch.Size([]), vector: torch.Size([3]), matrix: torch.Size([2, 3])\n",
      "Number of dimensions of scalar: 0, vector: 1, matrix: 2\n"
     ]
    }
   ],
   "source": [
    "# scalar\n",
    "scalar = torch.tensor(10)\n",
    "\n",
    "# vector\n",
    "vector = torch.tensor([10, 20, 30])\n",
    "\n",
    "# matrix\n",
    "matrix = torch.tensor([[10, 20, 30], [40, 50, 60]])\n",
    "\n",
    "# To check the shape of a tensor, use the .shape property\n",
    "print(f'Shape of scalar: {scalar.shape}, vector: {vector.shape}, matrix: {matrix.shape}')\n",
    "\n",
    "# To check the number of dimensions of a tensor, use the .ndim property\n",
    "print(f'Number of dimensions of scalar: {scalar.ndim}, vector: {vector.ndim}, matrix: {matrix.ndim}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many other methods for creating tensors, a few of which are listed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[5., 5., 5.],\n",
      "        [5., 5., 5.]])\n",
      "tensor([[0.2566, 0.7936, 0.9408],\n",
      "        [0.1332, 0.9346, 0.5936]])\n",
      "tensor([[ 2.2082, -0.6380,  0.4617],\n",
      "        [ 0.2674,  0.5349,  0.8094]])\n",
      "tensor([[9, 3, 1],\n",
      "        [9, 7, 9]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "t = torch.zeros(2, 3)                # creates a tensor with 0s, by passing the shape as arguments\n",
    "t_zeros = torch.zeros_like(t)        # zeros_like returns a new tensor, with the same shape as the input tensor, but filled with 0s\n",
    "t_ones = torch.ones(2, 3)            # creates a tensor with 1s\n",
    "t_fives = torch.empty(2, 3).fill_(5) # creates a non-initialized tensor and fills it with 5\n",
    "t_random = torch.rand(2, 3)          # creates a uniform random tensor\n",
    "t_normal = torch.randn(2, 3)         # creates a normal random tensor\n",
    "t_randint = torch.randint(low=0, high=10, size=(2, 3)) # creates a random tensor with integers between low and high (exclusive)\n",
    "\n",
    "np_array = np.zeros((2, 3))\n",
    "t_from_np = torch.from_numpy(np_array) # creates a tensor from a numpy array\n",
    "\n",
    "print(t_zeros)\n",
    "print(t_ones)\n",
    "print(t_fives)\n",
    "print(t_random)\n",
    "print(t_normal)\n",
    "print(t_randint)\n",
    "print(t_from_np)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the tensor dimensions can be direct arguments, or a collection like a\n",
    "tuple or list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9516, 0.0753, 0.8860],\n",
      "        [0.5832, 0.3376, 0.8090]])\n",
      "tensor([[0.5779, 0.9040, 0.5547],\n",
      "        [0.3423, 0.6343, 0.3644]])\n",
      "tensor([[0.7104, 0.9464, 0.7890],\n",
      "        [0.2814, 0.7886, 0.5895]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.rand(2, 3)\n",
    "print(t1)\n",
    "\n",
    "t2 = torch.rand((2, 3))\n",
    "print(t2)\n",
    "\n",
    "t3 = torch.rand([2, 3])\n",
    "print(t3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The underscore in `t_fives = torch.empty(2, 3).fill_(5)` signifies that the operation is performed in-place. For example, `t_fives.add_(5)` will add 5 to each element of the tensor `t_fives` in-place. Other examples of in-place operations are `t_fives.mul_(5)`, `t_fives.div_(5)`, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[10., 10., 10.],\n",
      "        [10., 10., 10.]])\n",
      "tensor([[10., 10., 10.],\n",
      "        [10., 10., 10.]])\n"
     ]
    }
   ],
   "source": [
    "t_fives_add = t_fives + 5\n",
    "print(t_fives_add)\n",
    "t_fives.add_(5) # in-place addition\n",
    "print(t_fives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n",
      "<class 'float'>\n"
     ]
    }
   ],
   "source": [
    "# Accesing the scalar value of a tensor\n",
    "print(t_fives[0, 1].item()) # item() returns the value of a tensor as a standard Python number\n",
    "print(type(t_fives[0, 1].item())) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations on Tensors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7539, 0.1952, 0.0050],\n",
      "        [0.3068, 0.1165, 0.9103]])\n",
      "tensor([[0.7539, 0.1952],\n",
      "        [0.0050, 0.3068],\n",
      "        [0.1165, 0.9103]])\n",
      "tensor([0.7539, 0.1952, 0.0050, 0.3068, 0.1165, 0.9103])\n",
      "tensor([[0.7539, 0.1952, 0.0050, 0.3068, 0.1165, 0.9103]])\n",
      "tensor([[0.7539],\n",
      "        [0.1952],\n",
      "        [0.0050],\n",
      "        [0.3068],\n",
      "        [0.1165],\n",
      "        [0.9103]])\n",
      "tensor([[0.7539, 0.1952],\n",
      "        [0.0050, 0.3068],\n",
      "        [0.1165, 0.9103]])\n",
      "tensor([[0.7539, 0.1952],\n",
      "        [0.0050, 0.3068],\n",
      "        [0.1165, 0.9103]])\n"
     ]
    }
   ],
   "source": [
    "# Reshape\n",
    "t = torch.rand(2, 3)\n",
    "print(t)\n",
    "print(t.reshape(3, 2))\n",
    "print(t.reshape(6))\n",
    "print(t.reshape(1, 6))\n",
    "print(t.reshape(6, 1))\n",
    "print(t.reshape(3, -1)) # -1 means \"infer the correct value from the shape of the tensor\"\n",
    "print(t.view(3, -1)) # view is an alternative to reshape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`view` and `reshape` gave the same result. What's the difference? \n",
    "\n",
    "`view()` will try to change the shape of the tensor while keeping the underlying data allocation the same, thus data will be shared between the two tensors. `reshape()` will create a new underlying memory allocation if necessary.\n",
    "\n",
    "When you use `reshape()` instead of view, the matrix is made contiguous if that is necessary, but otherwise the same data is used. This is nice if you don't care much about memory use. If you want to be sure that you're not accidentally copying a large matrix, `view()` is the way to go.\n",
    "\n",
    "Additional Reading: https://stackoverflow.com/questions/49643225/whats-the-difference-between-reshape-and-view-in-pytorch, https://discuss.pytorch.org/t/whats-the-difference-between-torch-reshape-vs-torch-view/159172/3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch Data Types"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Available data types include:\n",
    "\n",
    "```python\n",
    "torch.bool\n",
    "torch.int8\n",
    "torch.uint8\n",
    "torch.int16\n",
    "torch.int32\n",
    "torch.int64\n",
    "torch.half = torch.float16\n",
    "torch.float = torch.float32 (default datatype)\n",
    "torch.double = torch.float64\n",
    "torch.bfloat16\n",
    "```\n",
    "\n",
    "When not specified, the default is `torch.float32`, which differs from plain \n",
    "python where the default floating point datatype is `float64`.\n",
    "\n",
    "Ref: https://pytorch.org/tutorials/beginner/introyt/tensors_deeper_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1]], dtype=torch.int16)\n",
      "tensor([[3.0425, 5.3009, 2.6087],\n",
      "        [5.0371, 4.6682, 4.5133]], dtype=torch.float64)\n",
      "tensor([[3, 5, 2],\n",
      "        [5, 4, 4]], dtype=torch.int32)\n",
      "tensor([[-0.5687,  1.2580, -1.5890],\n",
      "        [-1.1208,  0.8423,  0.1744]])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones((2, 3), dtype=torch.int16) # creates a tensor with 1s of type int16\n",
    "print(a)\n",
    "\n",
    "b = torch.rand((2, 3), dtype=torch.float64) * 20 # creates a random tensor of type float64 and multiplies it by 20\n",
    "print(b)\n",
    "\n",
    "c = b.to(torch.int32) # converts the tensor of type float64 to type int32\n",
    "print(c)\n",
    "\n",
    "d = torch.randn([2, 3]) # creates a random tensor of type float32\n",
    "print(d)\n",
    "print(d.dtype)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also note that when the tensor is the default datatype, the `dtype` is not printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3383,  1.6992,  0.0109, -0.3387, -1.3407, -0.5854],\n",
      "        [ 0.5362,  0.5246, -1.4692,  1.4332,  0.7440, -0.4816],\n",
      "        [-1.0495,  0.6039, -0.3165,  0.5886, -0.8905,  0.4098],\n",
      "        [-1.4570, -0.1023, -0.5992,  0.4771, -0.1693,  0.2332],\n",
      "        [ 4.0356,  1.2795, -0.0127,  0.2408,  0.1325,  0.7642]]) torch.float32\n",
      "tensor([[ 0.3383,  1.6992,  0.0109, -0.3387, -1.3407, -0.5854],\n",
      "        [ 0.5362,  0.5246, -1.4692,  1.4332,  0.7440, -0.4816],\n",
      "        [-1.0495,  0.6039, -0.3165,  0.5886, -0.8905,  0.4098],\n",
      "        [-1.4570, -0.1023, -0.5992,  0.4771, -0.1693,  0.2332],\n",
      "        [ 4.0356,  1.2795, -0.0127,  0.2408,  0.1325,  0.7642]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[  0,   1,   0,   0, 255,   0],\n",
      "        [  0,   0, 255,   1,   0,   0],\n",
      "        [255,   0,   0,   0,   0,   0],\n",
      "        [255,   0,   0,   0,   0,   0],\n",
      "        [  4,   1,   0,   0,   0,   0]], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "t = torch.randn(5, 6)\n",
    "print(t, t.dtype)\n",
    "t = t.double()  # converts to 64-bit float\n",
    "print(t)\n",
    "t = t.byte()    # converts to unsigned 8-bit integer\n",
    "print(t)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ``torch.float16`` vs ``torch.float32``\n",
    "\n",
    "- Reduced Memory Usage:   \n",
    "    - ``torch.float16`` uses half as much memory per element compared to ``torch.float32``. This can be significant when dealing with large neural networks or datasets, especially on GPUs with limited memory.    \n",
    "    - It allows you to store and process larger models or batches of data.  \n",
    "    \n",
    "- Faster Computation and Reduced Bandwidth (While transferring from CPU to GPU, or across network connections)\n",
    "\n",
    "- Trade-offs: \n",
    "    - Reduced Precision - may lead to rounding errors in calculations.\n",
    "    - Not all deep learning models and operations are compatible with ``torch.float16``. Some operations may require ``torch.float32`` or higher precision to maintain accuracy.\n",
    "    - Training with ``torch.float16`` can be more challenging as it can lead to convergence issues, especially in complex models."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mathematical Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a+b = tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.]])\n",
      "\n",
      "c = tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.]])\n",
      "\n",
      "d = tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.]])\n",
      "\n",
      "fours = tensor([[4., 4., 4.],\n",
      "        [4., 4., 4.]])\n",
      "\n",
      "powers2 = tensor([[2., 4., 8.],\n",
      "        [2., 4., 8.]])\n",
      "\n",
      "c/powers2 = tensor([[1.0000, 0.5000, 0.2500],\n",
      "        [1.0000, 0.5000, 0.2500]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(2, 3)\n",
    "b = torch.ones(2, 3)\n",
    "print(f'a+b = {a+b}\\n')\n",
    "\n",
    "c = torch.ones(2, 3) * 2\n",
    "print(f'c = {c}\\n')\n",
    "\n",
    "d = torch.ones(2, 3) + 1 # broadcasting\n",
    "print(f'd = {d}\\n')\n",
    "\n",
    "fours = c ** 2 # element-wise exponentiation\n",
    "print(f'fours = {fours}\\n')\n",
    "\n",
    "powers2 = c ** torch.tensor([1, 2, 3]) # element-wise exponentiation with broadcasting\n",
    "print(f'powers2 = {powers2}\\n')\n",
    "\n",
    "print(f'c/powers2 = {c/powers2}\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix Multiplication: \n",
    "\n",
    "Things to keep in mind:\n",
    "* Inner dimensions must match (Ex: 2x3 and 3x4)\n",
    "* The resulting matrix has the shape of the outer dimensions (Ex: 2x4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4328, 0.2956, 0.2581, 0.1628],\n",
      "        [0.6889, 0.5091, 0.3646, 0.1278]]) torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "# Matrix multiplication\n",
    "\n",
    "A = torch.rand(2, 3)\n",
    "B = torch.rand(3, 4)\n",
    "C = torch.mm(A, B) # matrix multiplication\n",
    "print(C, C.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are other ways of performing matrix multiplication in PyTorch, such as torch.matmul(), torch.bmm(), and the @ operator. Read more at: https://www.geeksforgeeks.org/python-matrix-multiplication-using-pytorch/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing and Slicing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general PyTorch tensors behave similarly to Numpy arrays. They are zero indexed and support slicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8712, 0.1330, 0.4137],\n",
      "        [0.6044, 0.7581, 0.9037]])\n",
      "tensor(0.8712)\n",
      "tensor([0.8712, 0.1330, 0.4137])\n",
      "tensor([0.8712, 0.6044])\n",
      "tensor([[0.8712, 0.1330],\n",
      "        [0.6044, 0.7581]])\n"
     ]
    }
   ],
   "source": [
    "t = torch.rand(2, 3)\n",
    "print(t)\n",
    "print(t[0, 0]) # access a single element\n",
    "print(t[0, :]) # access a row\n",
    "print(t[:, 0]) # access a column\n",
    "print(t[0:2, 0:2]) # access a sub-matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.1330, 0.4137],\n",
      "        [0.6044, 0.7581, 0.9037]])\n",
      "tensor([[2.0000, 2.0000, 2.0000],\n",
      "        [0.6044, 0.7581, 0.9037]])\n",
      "tensor([[3.0000, 2.0000, 2.0000],\n",
      "        [3.0000, 0.7581, 0.9037]])\n",
      "tensor([[4.0000, 4.0000, 2.0000],\n",
      "        [4.0000, 4.0000, 0.9037]])\n"
     ]
    }
   ],
   "source": [
    "t[0, 0] = 1 # modify a single element\n",
    "print(t)\n",
    "t[0, :] = 2 # modify a row with implicit broadcasting\n",
    "print(t)\n",
    "t[:, 0] = 3 # modify a column with implicit broadcasting\n",
    "print(t)\n",
    "t[0:2, 0:2] = 4 # modify a sub-matrix with implicit broadcasting\n",
    "print(t)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Commonly used tensor methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before permute: torch.Size([2, 3, 4])\n",
      "After permute: torch.Size([3, 2, 4])\n",
      "After flatten on 2nd dim: torch.Size([3, 8])\n",
      "After flattening the resultant tensor: torch.Size([24])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [0, 1, 2]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.randn(2,3)\n",
    "t.max()                 # returns the maximum value in a tensor\n",
    "t.argmax()              # returns the index of the maximum value in a tensor.\n",
    "t.sum(dim=0)            # sum across rows\n",
    "t.sum(dim=1)            # sum across columns\n",
    "t.t()                   # transpose\n",
    "t.numel()               # number of elements in tensor\n",
    "t.nonzero()             # indices of non-zero elements\n",
    "t.squeeze()             # removes size 1 dimensions\n",
    "t.unsqueeze(0)          # inserts a dimension\n",
    "\n",
    "t = torch.rand(2, 3, 4)\n",
    "print('Before permute:', t.shape)\n",
    "t = t.permute(1, 0, 2)         # permutes dimensions: 1st dim becomes 2nd, 2nd becomes 1st, 3rd remains 3rd\n",
    "print('After permute:', t.shape)\n",
    "t = t.flatten(start_dim=1)     # flattens a tensor from the 2nd dimension\n",
    "print('After flatten on 2nd dim:', t.shape)\n",
    "t = t.flatten()                # flattens a tensor from the 1st dimension by default\n",
    "print('After flattening the resultant tensor:', t.shape)\n",
    "\n",
    "torch.dist(torch.tensor([3.0, 1.0]), torch.tensor([1.0, 2.0]), p=2) # computes the distance between two tensors, Returns the p-norm of (torch.tensor([3.0, 1.0]) - torch.tensor([1.0, 2.0])\n",
    "\n",
    "torch.arange(0, 10)     # tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "torch.eye(3, 3)         # creates a 3x3 matrix with 1s in the diagonal (identity in this case)\n",
    "t = torch.arange(0, 3)  # tensor([0, 1, 2])\n",
    "torch.cat((t, t))       # tensor([0, 1, 2, 0, 1, 2])\n",
    "torch.stack((t, t))     # tensor([[0, 1, 2],\n",
    "                        #         [0, 1, 2]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomness"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having a piece of code that behaves randomly and that spews out different results every time you run it is not a good idea. Athough, as programmers, we do not deal with true randomness, we deal with psuedo-randomness. But torch.randn does seem to give out different results everytime we run it, and by definition is random isn't it? \n",
    "\n",
    "In a way, yes. But, the random numbers are not quite truly random. They are pseudo-random numbers, which means that a number generator is used to generate a sequence of numbers that appear to be random, but they are not. The sequence of numbers generated by a pseudo-random number generator is determined by a fixed initial value called the seed. Every time we give it the same seed, it will give us the same sequence of numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False, False, False],\n",
      "        [False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "# Without setting the seed, the results of the random operations will be different every time\n",
    "\n",
    "random_1 = torch.rand(2, 3)\n",
    "random_2 = torch.rand(2, 3)\n",
    "\n",
    "print(random_1 == random_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False, False, False],\n",
      "        [False, False, False]])\n",
      "\n",
      "tensor([[True, True, True],\n",
      "        [True, True, True]])\n",
      "tensor([[True, True, True],\n",
      "        [True, True, True]])\n",
      "\n",
      "tensor([[True, True, True],\n",
      "        [True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "# By setting the seed, the results of the random operations will be the same every time\n",
    "\n",
    "torch.manual_seed(42)\n",
    "random_1 = torch.rand(2, 3)\n",
    "random_2 = torch.rand(2, 3)     # the second call to torch.rand(2, 3) will return different values than the first call\n",
    "print(random_1 == random_2)\n",
    "print()\n",
    "\n",
    "torch.manual_seed(42)\n",
    "random_3 = torch.rand(2, 3)\n",
    "random_4 = torch.rand(2, 3)     \n",
    "print(random_1 == random_3)\n",
    "print(random_2 == random_4)\n",
    "print()     \n",
    "\n",
    "torch.manual_seed(42)\n",
    "random_5 = torch.rand(2, 3)\n",
    "torch.manual_seed(42)           # need to reset the seed again, to get the same values for the second call to torch.rand(2, 3)\n",
    "random_6 = torch.rand(2, 3)\n",
    "print(random_5 == random_6)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When training a neural network, we use random initialization of weights, shuffling of data during training, and dropout, among other techniques. All these involve randomness, which can lead to slightly different results each time we run the code unless we set a seed. This can be problematic when trying to replicate someone elseâ€™s results or debugging your own code.\n",
    "\n",
    "Additional Reading: https://pieriantraining.com/how-to-set-the-seed-in-pytorch-for-reproducible-results/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. Create a tensor of shape (2, 3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b1d8c0fe9a67ee8cb4664b365ad36c03",
     "grade": false,
     "grade_id": "cell-463506e381066c6f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m tensor1 \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# YOUR CODE HERE\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m()\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(tensor1\u001b[39m.\u001b[39mshape)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Your solution code here\n",
    "tensor1 = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "print(tensor1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ad9e8454b563dc31594adebf6b3d6383",
     "grade": true,
     "grade_id": "cell-6ba79c91a62b0142",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert tensor1.shape == (2, 3, 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. Create an RGB image tensor of image shape 3x256x256 and having a pixel range between 0 and 255, with 3 equally spaced vertical strips of Red, Green, and Blue. Convert the image to GrayScale using the formula: Y' = 0.299 R + 0.587 G + 0.114 B"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desired RGB image   \n",
    "\n",
    "<img src=\"Q2_desired_image.jpeg\" alt=\"title\" width=\"500\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b4caa8ad04c5c475b7c709db24a7c2c4",
     "grade": false,
     "grade_id": "cell-b7f279a202f1a602",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a 3x256x256 dimensional tensor\n",
    "image_tensor = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Set values for Red, Green, and Blue strips\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Convert the RGB range [0, 255] to [0, 1]\n",
    "image_tensor /= 255.0\n",
    "\n",
    "# Convert RGB to Grayscale using the formula\n",
    "grayscale_tensor = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Convert PyTorch tensors to NumPy arrays for plotting\n",
    "# Make sure to use permute to switch the dimensions of the tensor to the correct order (H, W, C) for plotting.\n",
    "rgb_image_np = image_tensor.permute(1, 2, 0).numpy()\n",
    "grayscale_image_np = grayscale_tensor.numpy()\n",
    "\n",
    "# Plot the original RGB image\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(rgb_image_np)\n",
    "plt.title('Original RGB Image')\n",
    "plt.axis('off')\n",
    "\n",
    "# Plot the grayscale image\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(grayscale_image_np, cmap='gray')\n",
    "plt.title('Grayscale Image')\n",
    "plt.axis('off')\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4c9a1ed588b95a21f48a1c313bcf602e",
     "grade": true,
     "grade_id": "cell-e9a326c8a6c0409a",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert image_tensor.shape == (3, 256, 256)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thought experiments (No submissions required)\n",
    "\n",
    "- Why do we rescale the pixel values to be between 0 and 1? \n",
    "\n",
    "    - Normalizing the pixel values is a common practice in image processing. It helps in Numerical stability, ease in computation, and helps maintain consistency as many ML algorithms assume that the data is normalized.    \n",
    "<br>\n",
    "\n",
    "- Why did the Blue strip correspond to the Blackest strip in the grayscale image?\n",
    "\n",
    "    - Hint: Check the RGB to Grayscale conversion formula. The answer lies in the weights assigned to each color channel."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. Switch the Red and Blue stripes of the image obtained in Q2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "25e88cce2e798b2f52a618c647c22ab4",
     "grade": false,
     "grade_id": "cell-65abdea49e4328a5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Create a 3x256x256 dimensional tensor\n",
    "image_tensor = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Set values for Red, Green, and Blue strips (Note: the strips are switched)\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Convert the RGB range [0, 255] to [0, 1]\n",
    "image_tensor /= 255.0\n",
    "\n",
    "# Convert RGB to Grayscale using the formula\n",
    "grayscale_tensor = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Convert PyTorch tensors to NumPy arrays for plotting\n",
    "# Make sure to use permute to switch the dimensions of the tensor to the correct order (H, W, C) for plotting.\n",
    "rgb_image_np = image_tensor.permute(1, 2, 0).numpy()\n",
    "grayscale_image_np = grayscale_tensor.numpy()\n",
    "\n",
    "# Plot the Modified RGB image\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(rgb_image_np)\n",
    "plt.title('Modified RGB Image')\n",
    "plt.axis('off')\n",
    "\n",
    "# Plot the grayscale image\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(grayscale_image_np, cmap='gray')\n",
    "plt.title('Grayscale Image')\n",
    "plt.axis('off')\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eedcf50f03279fd4940ba3b183f2ce6b",
     "grade": true,
     "grade_id": "cell-c4c21329a9bd5510",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert image_tensor.shape == (3, 256, 256)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. Set the seed to 0 and Perform Matrix Multiplication on the two tensors below. Hint: You may need to transpose one of the tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "83915864923a1d1ea3845d1b21d8edcc",
     "grade": false,
     "grade_id": "cell-657d613c074a112e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# 3 Set the seed to 0 and Perform Matrix Multiplication on the two tensors below. Hint: You may need to transpose one of the tensors.\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "X = torch.rand(3, 7)\n",
    "Y = torch.rand(4, 7)\n",
    "\n",
    "R = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "R\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ae1a5173a274c3bac67660766d7f0382",
     "grade": true,
     "grade_id": "cell-094dfc93c2007161",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert R.shape == (4, 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. Get the maximum value and its index across (i) each row of tensor R, (ii) each column of tensor R, and (iii) the entire tensor R.\n",
    "\n",
    "Note: .max() returns a namedtuple (values, indices) where values is the maximum value of each row of the tensor R, and indices is the index of the maximum value of each row of the tensor R. Make sure to return the values and indices separately in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4df216f5f827ce73793e4cb4308ab54a",
     "grade": false,
     "grade_id": "cell-fe9a19d254ba01cf",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Max value across the rows\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "print(R_max_rows, R_max_rows_index)\n",
    "\n",
    "# Max value across the columns\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "print(R_max_cols, R_max_cols_index)\n",
    "\n",
    "# Max value across all the elements\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "print(R_max, R_max_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3b9ec5e2de5c38a322f04829f3e1f164",
     "grade": true,
     "grade_id": "cell-429a95d34f8ce52b",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert R.shape == (4, 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6. Set Seed to 0. Create a tensor of shape (2, 3) and find the indices of the elements that are greater than the mean of the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f639840b96390ebe0e639f609e0e1d1a",
     "grade": false,
     "grade_id": "cell-488c071bf48dc89c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Create a tensor of shape (2, 3) and find the indices of the elements that are greater than the mean of the tensor.\n",
    "\n",
    "torch.manual_seed(0)\n",
    "tensor = torch.rand(2, 3)\n",
    "print(tensor)\n",
    "indices = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "31db839a4623df2da07e7fa2add5f32f",
     "grade": true,
     "grade_id": "cell-4233571e9cf0b3a4",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert tensor.shape == (2, 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7. Compute the mean tensor of each class. The mean tensor can be considered as the prototype of the batch. For the following tensors, assign the class label to each tensor based on the distance between the tensor and the prototypes (use torch.dist(...))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5569e21d33c0ab1a6016c7bc87501572",
     "grade": false,
     "grade_id": "cell-206e7137d074bfaa",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(2)\n",
    "\n",
    "class_A_tensors = torch.vstack([torch.randint(0, 10, size=(2,), dtype=torch.float32) for _ in range(10)])\n",
    "class_B_tensors = torch.vstack([torch.randint(10, 20, size=(2,), dtype=torch.float32) for _ in range(10)])\n",
    "class_C_tensors = torch.vstack([torch.randint(20, 30, size=(2,), dtype=torch.float32) for _ in range(10)])\n",
    "\n",
    "class_A_prototype = None\n",
    "class_B_prototype = None\n",
    "class_C_prototype = None\n",
    "\n",
    "# Compute the prototypes\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Plot the tensors\n",
    "plt.scatter(class_A_tensors[:, 0], class_A_tensors[:, 1], label='Class A', marker='o', color='red')\n",
    "plt.scatter(class_B_tensors[:, 0], class_B_tensors[:, 1], label='Class B', marker='s', color='green')\n",
    "plt.scatter(class_C_tensors[:, 0], class_C_tensors[:, 1], label='Class C', marker='^', color='blue')\n",
    "\n",
    "# Plot the prototypes\n",
    "plt.scatter(class_A_prototype[0], class_A_prototype[1], label='Prototype A', marker='*', s=200, color='red')\n",
    "plt.scatter(class_B_prototype[0], class_B_prototype[1], label='Prototype B', marker='*', s=200, color='green')\n",
    "plt.scatter(class_C_prototype[0], class_C_prototype[1], label='Prototype C', marker='*', s=200, color='blue')\n",
    "\n",
    "plt.title('Tensors from Different Classes')\n",
    "plt.xlabel('Dimension 1')\n",
    "plt.ylabel('Dimension 2')\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "49860a55ea3eed035cf94360640ec2d7",
     "grade": false,
     "grade_id": "cell-4d3f07ea0a70956b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(2)\n",
    "tensor_list = torch.vstack([torch.randint(0, 30, size=(2,), dtype=torch.float32) for _ in range(50)])\n",
    "\n",
    "# assign each tensor in tensor_list to a class using the minimum distance to a prototype and populate the following lists\n",
    "class_A_tensors = []\n",
    "class_B_tensors = []\n",
    "class_C_tensors = []\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "class_A_tensors = torch.vstack(class_A_tensors)\n",
    "class_B_tensors = torch.vstack(class_B_tensors)\n",
    "class_C_tensors = torch.vstack(class_C_tensors)\n",
    "\n",
    "# plot the new tensors assigned to each class and the original prototypes\n",
    "plt.scatter(class_A_tensors[:, 0], class_A_tensors[:, 1], label='Class A', marker='o', color='red')\n",
    "plt.scatter(class_B_tensors[:, 0], class_B_tensors[:, 1], label='Class B', marker='s', color='green')\n",
    "plt.scatter(class_C_tensors[:, 0], class_C_tensors[:, 1], label='Class C', marker='^', color='blue')\n",
    "\n",
    "plt.scatter(class_A_prototype[0], class_A_prototype[1], label='Prototype A', marker='*', s=200, color='red')\n",
    "plt.scatter(class_B_prototype[0], class_B_prototype[1], label='Prototype B', marker='*', s=200, color='green')\n",
    "plt.scatter(class_C_prototype[0], class_C_prototype[1], label='Prototype C', marker='*', s=200, color='blue')\n",
    "\n",
    "plt.title('Tensors Assigned to Classes')\n",
    "plt.xlabel('Dimension 1')\n",
    "plt.ylabel('Dimension 2')\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8b3da4ed7651a1e1a6603d5c6048855f",
     "grade": true,
     "grade_id": "cell-d134488ac45231bc",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(class_A_tensors) > 0\n",
    "assert len(class_B_tensors) > 0\n",
    "assert len(class_C_tensors) > 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Side Note**: Such an approach is used in Few Shot Learning, where we have a few examples of each class and we need to classify a new example into one of the classes. The mean tensor of each class is considered as the prototype of the class.\n",
    "\n",
    "Prototypical Networks are used to generate the M dimensional embedding of the input image. The M dimensional embedding is then used to compute the distance between the input image and the prototype of each class. The class with the minimum distance is assigned to the input image.\n",
    "\n",
    "Reading: https://analyticsindiamag.com/what-are-prototypical-networks/, https://arxiv.org/pdf/1703.05175.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
