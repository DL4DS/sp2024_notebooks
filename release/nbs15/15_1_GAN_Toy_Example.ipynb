{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While editing this notebook, don't change cell types as that confuses the autograder.\n",
    "\n",
    "Before you turn this notebook in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel $\\rightarrow$ Restart) and then **run all cells** (in the menubar, select Cell $\\rightarrow$ Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Understanding Deep Learning_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "view-in-github",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "733ad8bc85a8968157abd4c7a8ca7931",
     "grade": false,
     "grade_id": "cell-42212f7033f655b7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/DL4DS/sp2024_notebooks/blob/main/release/nbs15/15_1_GAN_Toy_Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "t9vk9Elugvmi",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "180ccbad28747be8367df4590b522a39",
     "grade": false,
     "grade_id": "cell-b44b9a2fab55aac5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Notebook 15.1: GAN Toy example\n",
    "\n",
    "This notebook investigates the GAN toy example as illustrated in figure 15.1 in the book.\n",
    "\n",
    "One difference from the example in the book is that we are not drawing a new random sample\n",
    "on each GAN iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OLComQyvCIJ7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y_OkVWmam4Qx"
   },
   "outputs": [],
   "source": [
    "# Get a batch of real data.  Our goal is to make data that looks like this.\n",
    "def get_real_data_batch(n_sample):\n",
    "  np.random.seed(0)\n",
    "  x_true = np.random.normal(size=(1,n_sample)) + 7.5\n",
    "  return x_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RFpL0uCXoTpV"
   },
   "source": [
    "Define our generator.  This takes a standard normally-distributed latent variable $z$ and adds a scalar $\\theta$ to this, where $\\theta$ is the single parameter of this generative model according to:\n",
    "\n",
    "\\begin{equation}\n",
    "x_i = z_i + \\theta.\n",
    "\\end{equation}\n",
    "\n",
    "Obviously this model can generate the family of Gaussian distributions with unit variance, but different means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OtLQvf3Enfyw"
   },
   "outputs": [],
   "source": [
    "# This is our generator -- takes the single parameter theta\n",
    "# of the generative model, adds it to each element of z, and\n",
    "# returns the result.\n",
    "def generator(z, theta):\n",
    "    x_gen = z + theta\n",
    "    return x_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xrzd8aehYAYR"
   },
   "source": [
    "Now, we define our discriminator.  This is a simple logistic regression model (1D linear model passed through sigmoid) that returns the probability that the data is real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vHBgAFZMsnaC"
   },
   "outputs": [],
   "source": [
    "# Define our discriminative model\n",
    "\n",
    "# Logistic sigmoid, maps from [-infty,infty] to [0,1]\n",
    "def sigmoid(data_in):\n",
    "  return  1.0 / (1.0+np.exp(-data_in))\n",
    "\n",
    "# Discriminator computes y\n",
    "def discriminator(x, phi0, phi1):\n",
    "  return sigmoid(phi0 + phi1 * x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V1FiDBhepcQJ"
   },
   "outputs": [],
   "source": [
    "# Draws a figure like Figure 15.1a\n",
    "def draw_data_model(x_real, x_syn, phi0=None, phi1=None):\n",
    "  fix, ax = plt.subplots();\n",
    "\n",
    "  for x in x_syn:\n",
    "    ax.plot([x,x],[0,0.33],color='#f47a60')\n",
    "  for x in x_real:\n",
    "    ax.plot([x,x],[0,0.33],color='#7fe7dc')\n",
    "\n",
    "  if phi0 is not None:\n",
    "    x_model = np.arange(0,10,0.01)\n",
    "    y_model = discriminator(x_model, phi0, phi1)\n",
    "    ax.plot(x_model, y_model,color='#dddddd')\n",
    "  ax.set_xlim([0,10])\n",
    "  ax.set_ylim([0,1])\n",
    "\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U8pFb497x36n"
   },
   "outputs": [],
   "source": [
    "# Get data batch\n",
    "x_real = get_real_data_batch(10)\n",
    "\n",
    "# Initialize generator and synthesize a batch of examples\n",
    "theta = 3.0\n",
    "np.random.seed(1)\n",
    "z = np.random.normal(size=(1,10))\n",
    "x_syn = generator(z, theta)\n",
    "\n",
    "# Initialize discriminator model\n",
    "phi0 = -2\n",
    "phi1 = 1\n",
    "\n",
    "print(\"Generated and real samples along with untrained discriminator plot.\")\n",
    "draw_data_model(x_real, x_syn, phi0, phi1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SNDV1G5PYhcQ"
   },
   "source": [
    "You can see that the synthesized (orange) samples don't look much like the real (cyan) ones, and the initial model to discriminate them (gray line represents probability of being real) is pretty bad as well.\n",
    "\n",
    "Let's deal with the discriminator first.  Let's define the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "Bc3VwCabYcfg",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3bca38386d7e82a713a3e3d31cf76a28",
     "grade": false,
     "grade_id": "cell-183d3a6a5db4d978",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Discriminator loss\n",
    "def compute_discriminator_loss(x_real, x_syn, phi0, phi1):\n",
    "\n",
    "  # TODO -- compute the loss for the discriminator\n",
    "  # Run the real data and the synthetic data through the discriminator\n",
    "  # Then use the standard binary cross entropy loss with the y=1 for the real samples\n",
    "  # and y=0 for the synthesized ones.\n",
    "  #\n",
    "  # See Section 15.1.1 and 15.1.2\n",
    "  \n",
    "  # YOUR CODE HERE\n",
    "  raise NotImplementedError()\n",
    "\n",
    "\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "MiqM3GXSbn0z",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6625cbc24fbf44bfc32df604b8831724",
     "grade": true,
     "grade_id": "cell-b9e0e4d5d7dca59d",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test the loss\n",
    "loss = compute_discriminator_loss(x_real, x_syn, phi0, phi1)\n",
    "print(\"True Loss = 13.814757170851447, Your loss=\", loss )\n",
    "\n",
    "assert np.abs(loss - 13.814757170851447) < 1e-5, \"Loss is incorrect\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zAxUPo3p0CIW"
   },
   "outputs": [],
   "source": [
    "def compute_discriminator_gradient(x_real, x_syn, phi0, phi1):\n",
    "  \"\"\"\n",
    "  Approximate the gradient of the discriminator loss with respect to phi0 and phi1 using finite differences.\n",
    "  \"\"\"\n",
    "  delta = 0.0001;\n",
    "  loss1 = compute_discriminator_loss(x_real, x_syn, phi0, phi1)\n",
    "  loss2 = compute_discriminator_loss(x_real, x_syn, phi0+delta, phi1)\n",
    "  loss3 = compute_discriminator_loss(x_real, x_syn, phi0, phi1+delta)\n",
    "  dl_dphi0 = (loss2-loss1) / delta\n",
    "  dl_dphi1 = (loss3-loss1) / delta\n",
    "\n",
    "  return dl_dphi0, dl_dphi1\n",
    "\n",
    "def update_discriminator(x_real, x_syn, n_iter, phi0, phi1):\n",
    "  \"\"\"\n",
    "  Perform n_iter steps of gradient descent on the discriminator loss function\n",
    "  with a fixed, hardcoded learning rate.\n",
    "  \"\"\"\n",
    "\n",
    "  # Define learning rate\n",
    "  alpha = 0.01\n",
    "\n",
    "  # Get derivatives\n",
    "  print(\"Initial discriminator loss = \", compute_discriminator_loss(x_real, x_syn, phi0, phi1))\n",
    "  for iter in range(n_iter):\n",
    "    # Get gradient\n",
    "    dl_dphi0, dl_dphi1 = compute_discriminator_gradient(x_real, x_syn, phi0, phi1)\n",
    "    # Take a gradient step downhill\n",
    "    phi0 = phi0 - alpha * dl_dphi0 ;\n",
    "    phi1 = phi1 - alpha * dl_dphi1 ;\n",
    "\n",
    "  print(\"Final Discriminator Loss= \", compute_discriminator_loss(x_real, x_syn, phi0, phi1))\n",
    "\n",
    "  return phi0, phi1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FE_DeweeAbMc"
   },
   "outputs": [],
   "source": [
    "# Let's update the discriminator (sigmoid curve)\n",
    "n_iter = 100\n",
    "print(\"Initial parameters (phi0,phi1)\", phi0, phi1)\n",
    "\n",
    "phi0, phi1 = update_discriminator(x_real, x_syn, n_iter, phi0, phi1)\n",
    "\n",
    "print(\"Final parameters (phi0,phi1)\", phi0, phi1)\n",
    "\n",
    "draw_data_model(x_real, x_syn, phi0, phi1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pRv9myh0d3Xm"
   },
   "source": [
    "Now let's update the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "5uiLrFBvJFAr",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a57e5f1847bae7aed9b024508bbfe8f0",
     "grade": false,
     "grade_id": "cell-fc7fe28ba107e4db",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_generator_loss(z, theta, phi0, phi1):\n",
    "  # TODO:\n",
    "  # 1. Run the generator on the latent variables z with the parameters theta\n",
    "  #    to generate new data x_syn\n",
    "  # 2. Then run the discriminator on the new data to get the probability of being real\n",
    "  # 3. The loss is the total negative log probability of being synthesized (i.e. of not being real)\n",
    "  \n",
    "  # YOUR CODE HERE\n",
    "  raise NotImplementedError()\n",
    "\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "cqnU3dGPd6NK",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "71cc7e94083588e077fd4b46e0834495",
     "grade": true,
     "grade_id": "cell-de8c0b28976f760e",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test generator loss to check you have it correct\n",
    "loss = compute_generator_loss(z, theta, -2, 1)\n",
    "print(\"True Loss = 13.78437035945412, Your loss=\", loss )\n",
    "\n",
    "assert np.abs(loss - 13.78437035945412) < 1e-5, \"Loss is incorrect\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P1Lqy922dqal"
   },
   "outputs": [],
   "source": [
    "def compute_generator_gradient(z, theta, phi0, phi1):\n",
    "  \"\"\"\n",
    "  Approximate the gradient of the generator loss with respect to theta using finite differences.\n",
    "  \"\"\"\n",
    "  delta = 0.0001\n",
    "  loss1 = compute_generator_loss(z,theta, phi0, phi1) ;\n",
    "  loss2 = compute_generator_loss(z,theta+delta, phi0, phi1) ;\n",
    "  dl_dtheta = (loss2-loss1)/ delta\n",
    "  return dl_dtheta\n",
    "\n",
    "def update_generator(z, theta, n_iter, phi0, phi1):\n",
    "    \"\"\"\n",
    "    Perform n_iter steps of gradient _ascent_ on the generator loss function\n",
    "    \"\"\"\n",
    "    # Define learning rate\n",
    "    alpha = 0.02\n",
    "\n",
    "    # Get derivatives\n",
    "    print(\"Initial generator loss = \", compute_generator_loss(z, theta, phi0, phi1))\n",
    "    for iter in range(n_iter):\n",
    "      # Get gradient\n",
    "      dl_dtheta = compute_generator_gradient(x_real, x_syn, phi0, phi1)\n",
    "      \n",
    "      # Take a gradient step (uphill, since we are trying to make synthesized data less well classified by discriminator)\n",
    "      theta = theta + alpha * dl_dtheta ;\n",
    "\n",
    "    print(\"Final generator loss = \", compute_generator_loss(z, theta, phi0, phi1))\n",
    "    return theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q6kUkMO1P8V0"
   },
   "outputs": [],
   "source": [
    "n_iter = 10\n",
    "theta = 3.0\n",
    "print(\"Theta before\", theta)\n",
    "theta = update_generator(z, theta, n_iter, phi0, phi1)\n",
    "print(\"Theta after\", theta)\n",
    "\n",
    "x_syn = generator(z,theta)\n",
    "draw_data_model(x_real, x_syn, phi0, phi1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pcbdK2agTO-y"
   },
   "outputs": [],
   "source": [
    "# Now let's define a full GAN loop\n",
    "\n",
    "# Initialize the parameters\n",
    "theta = 3\n",
    "phi0 = -2\n",
    "phi1 = 1\n",
    "\n",
    "np.random.seed(1)\n",
    "z = np.random.normal(size=(1,10))\n",
    "\n",
    "# Number of iterations for updating generator and discriminator\n",
    "n_iter_discrim = 300\n",
    "n_iter_gen = 3\n",
    "\n",
    "print(\"Initial parameters (phi0,phi1) of the discriminator\", phi0, phi1)\n",
    "for c_gan_iter in range(5):  # originally 5. Feel free to experiment with more iterations\n",
    "\n",
    "  print(\"====================================\")\n",
    "  print(\"GAN iteration\", c_gan_iter)\n",
    "  print(\"====================================\")\n",
    "\n",
    "  # Run generator to produce synthesized data\n",
    "  x_syn = generator(z, theta)\n",
    "\n",
    "  print(\"Synthesized data\")\n",
    "  draw_data_model(x_real, x_syn, phi0, phi1)\n",
    "\n",
    "  # Update the discriminator\n",
    "  print(\"Updating discriminator\")\n",
    "  phi0, phi1 = update_discriminator(x_real, x_syn, n_iter_discrim, phi0, phi1)\n",
    "  draw_data_model(x_real, x_syn, phi0, phi1)\n",
    "\n",
    "  # Update the generator\n",
    "  print(\"Updating generator\")\n",
    "  theta = update_generator(z, theta, n_iter_gen, phi0, phi1)\n",
    "\n",
    "print(\"Final parameters (phi0,phi1)\", phi0, phi1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "loMx0TQUgBs7"
   },
   "source": [
    "You can see that the synthesized data (orange) is becoming closer to the true data (cyan).  However, this is extremely unstable -- as you will find if you mess around with the number of iterations of each optimization and the total iterations overall."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM0StKV3FIZ3MZqfflqC0Rv",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
